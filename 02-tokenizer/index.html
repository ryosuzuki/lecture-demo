<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Tiny Tokenizer Trainer (Toy BPE) — single-file demo</title>
  <style>
    :root { color-scheme: light dark; }
    body {
      font-family: system-ui, -apple-system, "Segoe UI", Roboto, "Noto Sans", sans-serif;
      margin: 0;
      padding: 20px;
      line-height: 1.5;
    }
    h1 { font-size: 20px; margin: 0 0 12px; }
    h2 { font-size: 16px; margin: 18px 0 8px; }
    .muted { font-size: 12px; opacity: 0.75; }
    .grid {
      display: grid;
      grid-template-columns: 1.15fr 0.85fr;
      gap: 16px;
      align-items: start;
    }
    @media (max-width: 980px) { .grid { grid-template-columns: 1fr; } }

    .card {
      border: 1px solid rgba(128,128,128,0.35);
      border-radius: 14px;
      padding: 12px;
      background: rgba(128,128,128,0.06);
    }
    textarea, input[type="text"] {
      width: 100%;
      box-sizing: border-box;
      padding: 10px;
      border-radius: 10px;
      border: 1px solid rgba(128,128,128,0.4);
      background: transparent;
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Noto Sans Mono", monospace;
      font-size: 13px;
    }
    textarea { min-height: 170px; }

    .row { display: flex; gap: 10px; flex-wrap: wrap; align-items: center; }
    label { font-size: 13px; opacity: 0.9; }
    select, input[type="number"], input[type="file"] {
      padding: 6px 8px;
      border-radius: 10px;
      border: 1px solid rgba(128,128,128,0.4);
      background: transparent;
    }
    button {
      padding: 8px 10px;
      border-radius: 12px;
      border: 1px solid rgba(128,128,128,0.45);
      background: rgba(128,128,128,0.12);
      cursor: pointer;
    }
    button:hover { filter: brightness(1.05); }
    button:disabled { opacity: 0.55; cursor: not-allowed; }

    .stats {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 8px;
      font-size: 13px;
      margin-top: 10px;
    }
    .pill {
      display: inline-block;
      padding: 2px 8px;
      border-radius: 999px;
      border: 1px solid rgba(128,128,128,0.35);
      background: rgba(128,128,128,0.10);
      font-size: 12px;
    }

    details summary { cursor: pointer; }

    table { width: 100%; border-collapse: collapse; font-size: 12px; }
    th, td {
      border-bottom: 1px solid rgba(128,128,128,0.25);
      padding: 6px 4px;
      text-align: left;
      vertical-align: top;
    }
    th { opacity: 0.85; font-weight: 600; }

    .chipRow {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      align-items: center;
    }
    .chip {
      display: inline-block;
      padding: 2px 8px;
      border-radius: 999px;
      border: 1px solid rgba(128,128,128,0.35);
      background: rgba(128,128,128,0.10);
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Noto Sans Mono", monospace;
      font-size: 12px;
      max-width: 240px;
      overflow: hidden;
      text-overflow: ellipsis;
      white-space: nowrap;
    }
    .chip.strong {
      border-color: rgba(128,128,128,0.55);
      background: rgba(128,128,128,0.18);
    }
    code.k {
      padding: 2px 6px;
      border-radius: 8px;
      background: rgba(128,128,128,0.12);
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Noto Sans Mono", monospace;
      font-size: 12px;
    }

    .bar {
      height: 10px;
      border-radius: 999px;
      border: 1px solid rgba(128,128,128,0.35);
      overflow: hidden;
      background: rgba(128,128,128,0.08);
      position: relative;
    }
    .bar > div {
      height: 100%;
      width: 0%;
      background: rgba(100,160,255,0.45);
    }
    .small { font-size: 12px; }
  </style>
</head>

<body>
  <h1>Tiny Tokenizer Trainer (Toy BPE) — step-by-step tokenizer learning</h1>
  <div class="muted">
    This demo shows how a tokenizer can “learn” larger tokens by repeatedly merging the most frequent adjacent token pair.
    We use <strong>▁</strong> as a whitespace marker (similar to SentencePiece-style tokenizers).
  </div>

  <div class="grid" style="margin-top: 12px;">
    <div class="card">
      <h2>1) Training corpus</h2>

      <div class="row" style="margin-bottom: 8px;">
        <label for="fileInput">Load .txt:</label>
        <input id="fileInput" type="file" accept=".txt,text/plain" />

        <button id="initBtn" title="Reset to character-level tokens">Initialize / Reset</button>
        <button id="undoBtn" disabled>Undo 1 merge</button>

        <button id="stepBtn" disabled title="Merge the most frequent pair once">Step (best merge)</button>

        <label>Run:</label>
        <input id="runN" type="number" min="1" max="500" value="10" style="width: 90px;" />
        <button id="runBtn" disabled>Run N merges</button>
        <button id="stopBtn" disabled>Stop</button>
      </div>

      <textarea id="corpusText"></textarea>

      <div class="row" style="margin-top: 10px;">
        <label><input id="lowercase" type="checkbox" checked /> Lowercase</label>
        <label><input id="collapseWs" type="checkbox" checked /> Collapse whitespace</label>
        <label><input id="showSpaceAsVisible" type="checkbox" checked /> Display ▁ as ␠</label>
      </div>

      <div class="stats">
        <div>State: <span class="pill" id="statePill">Not initialized</span></div>
        <div>Merges applied: <span class="pill" id="mergesPill">0</span></div>
        <div>Vocabulary size: <span class="pill" id="vocabPill">-</span></div>
        <div>Total symbols (corpus): <span class="pill" id="symbolsPill">-</span></div>
      </div>

      <details style="margin-top: 12px;" open>
        <summary><strong>What happens at each step?</strong></summary>
        <div class="muted" style="margin-top: 8px;">
          <ol style="margin: 6px 0 0 18px;">
            <li>Start with character-level tokens (plus a whitespace marker).</li>
            <li>Count all adjacent token pairs in the corpus.</li>
            <li>Pick the most frequent pair.</li>
            <li>Merge it into a new token and repeat.</li>
          </ol>
          This is a simplified BPE trainer. Real LLM tokenizers may operate at the byte level, include special tokens, and use different pre/post-processing.
        </div>
      </details>

      <details style="margin-top: 12px;">
        <summary>Merge history</summary>
        <div id="mergeHistory" class="muted" style="margin-top: 8px;">(none yet)</div>
      </details>

      <details style="margin-top: 12px;">
        <summary>Vocabulary (first 200 tokens)</summary>
        <div id="vocabView" class="muted" style="margin-top: 8px;">(initialize first)</div>
      </details>
    </div>

    <div class="card">
      <h2>2) Next merge candidates (pair frequencies)</h2>

      <div class="muted">
        The “best merge” is the most frequent adjacent pair in the current tokenization of the corpus.
        You can also click <em>Merge</em> for any pair to explore alternatives.
      </div>

      <div style="margin-top: 10px;">
        <div class="row">
          <div>Next best pair: <span class="pill" id="bestPairPill">-</span></div>
          <div>Count: <span class="pill" id="bestCountPill">-</span></div>
        </div>
      </div>

      <div style="margin-top: 10px;">
        <div class="muted">Top pairs (current):</div>
        <div id="pairsTableWrap" style="margin-top: 6px;"></div>
      </div>

      <h2 style="margin-top: 18px;">3) Tokenize new text with the learned merges</h2>
      <div class="muted">
        Type a sentence and see how the current merge rules segment it into tokens.
        (Whitespace becomes <code class="k">▁</code> internally.)
      </div>

      <div style="margin-top: 10px;">
        <input id="inputText" type="text" value="I like language models." />
      </div>

      <div class="row" style="margin-top: 10px;">
        <button id="tokenizeBtn" disabled>Tokenize</button>
        <label><input id="autoTokenize" type="checkbox" checked /> Auto-update after each merge</label>
      </div>

      <div style="margin-top: 10px;">
        <div class="muted">Tokens:</div>
        <div id="tokenOutput" class="chipRow" style="margin-top: 6px;"></div>
        <div class="muted" id="tokenStats" style="margin-top: 8px;"></div>
      </div>

      <details style="margin-top: 12px;">
        <summary>Show step-by-step encoding for this input</summary>
        <div id="encodeSteps" class="muted" style="margin-top: 8px;"></div>
      </details>
    </div>
  </div>

  <div class="card" style="margin-top: 16px;">
    <h2>4) Corpus visualization (current tokenization)</h2>
    <div class="row">
      <label>Show first:</label>
      <input id="showLines" type="number" min="1" max="200" value="10" style="width: 90px;" />
      <span class="muted">lines</span>
      <button id="refreshCorpusBtn" disabled>Refresh view</button>
    </div>

    <div class="muted" style="margin-top: 8px;">
      Each line is displayed as a sequence of tokens. As you merge pairs, tokens become longer (e.g., <code class="k">▁l</code> + <code class="k">ike</code> → <code class="k">▁like</code>).
    </div>

    <div id="corpusView" style="margin-top: 12px;"></div>
  </div>

<script>
(() => {
  const $ = (id) => document.getElementById(id);

  // UI elements
  const corpusText = $("corpusText");
  const fileInput = $("fileInput");
  const initBtn = $("initBtn");
  const undoBtn = $("undoBtn");
  const stepBtn = $("stepBtn");
  const runBtn = $("runBtn");
  const stopBtn = $("stopBtn");
  const runN = $("runN");
  const lowercase = $("lowercase");
  const collapseWs = $("collapseWs");
  const showSpaceAsVisible = $("showSpaceAsVisible");

  const statePill = $("statePill");
  const mergesPill = $("mergesPill");
  const vocabPill = $("vocabPill");
  const symbolsPill = $("symbolsPill");

  const bestPairPill = $("bestPairPill");
  const bestCountPill = $("bestCountPill");
  const pairsTableWrap = $("pairsTableWrap");

  const mergeHistory = $("mergeHistory");
  const vocabView = $("vocabView");

  const inputText = $("inputText");
  const tokenizeBtn = $("tokenizeBtn");
  const autoTokenize = $("autoTokenize");
  const tokenOutput = $("tokenOutput");
  const tokenStats = $("tokenStats");
  const encodeSteps = $("encodeSteps");

  const showLines = $("showLines");
  const refreshCorpusBtn = $("refreshCorpusBtn");
  const corpusView = $("corpusView");

  // Sample corpus (auto-loaded on page open)
  const DEFAULT_SAMPLE =
`I like machine learning.
I like natural language processing.
I like generative AI.
We build simple language models.
Language models predict the next word.
Students like interactive demos.
This demo is a tiny n-gram model.
Generative models can sample tokens.
Probability distributions can be visualized.
I like teaching in class.`;

  // Internal representation:
  // - We replace spaces with "▁" and also add a leading "▁" at start of each line.
  const SPACE_MARK = "▁";
  const SEP = "\u0001"; // pair key separator (unlikely to appear)

  let initialized = false;
  let isRunning = false;

  // Data
  let originalLines = [];     // preprocessed string lines (with SPACE_MARK, but still plain string)
  let baseSequences = [];     // initial sequences as arrays of symbols (characters)
  let sequences = [];         // current sequences after merges (arrays of symbols)
  let merges = [];            // [{a,b,merged,countAtMerge}]
  let vocabSet = new Set();   // symbols currently in vocab (for display)
  let lastPairCounts = new Map(); // cache for UI

  function escapeHtml(s) {
    return String(s)
      .replaceAll("&", "&amp;")
      .replaceAll("<", "&lt;")
      .replaceAll(">", "&gt;")
      .replaceAll('"', "&quot;")
      .replaceAll("'", "&#039;");
  }

  function displayToken(tok) {
    // display whitespace marker as visible "␠" if checkbox is on
    const visibleSpace = "␠";
    if (!showSpaceAsVisible.checked) return tok;
    return tok.split(SPACE_MARK).join(visibleSpace);
  }

  function preprocessCorpus(raw) {
    let text = raw.replace(/\r\n?/g, "\n");
    if (lowercase.checked) text = text.toLowerCase();

    const lines = text.split("\n")
      .map(l => l.trim())
      .filter(l => l.length > 0)
      .map(l => {
        let x = l;
        if (collapseWs.checked) x = x.replace(/\s+/g, " ");
        // Add leading space marker (common in SP-like tokenizers)
        x = SPACE_MARK + x;
        // Replace spaces with SPACE_MARK
        x = x.replaceAll(" ", SPACE_MARK);
        return x;
      });

    return lines;
  }

  function init() {
    initialized = false;
    isRunning = false;
    stopBtn.disabled = true;

    originalLines = preprocessCorpus(corpusText.value);
    baseSequences = originalLines.map(line => Array.from(line));
    sequences = baseSequences.map(seq => seq.slice()); // deep-ish copy
    merges = [];
    vocabSet = new Set();
    for (const seq of sequences) for (const s of seq) vocabSet.add(s);

    initialized = originalLines.length > 0;
    statePill.textContent = initialized ? "Initialized (char-level)" : "Not enough data";
    mergesPill.textContent = "0";
    vocabPill.textContent = initialized ? String(vocabSet.size) : "-";
    symbolsPill.textContent = initialized ? String(totalSymbolCount(sequences)) : "-";

    undoBtn.disabled = !(initialized && merges.length > 0);
    stepBtn.disabled = !initialized;
    runBtn.disabled = !initialized;
    tokenizeBtn.disabled = !initialized;
    refreshCorpusBtn.disabled = !initialized;

    updateAllViews();

    if (initialized && autoTokenize.checked) tokenizeInput();
  }

  function totalSymbolCount(seqList) {
    let n = 0;
    for (const seq of seqList) n += seq.length;
    return n;
  }

  function pairKey(a, b) { return a + SEP + b; }

  function computePairCounts() {
    const counts = new Map();
    for (const seq of sequences) {
      for (let i = 0; i < seq.length - 1; i++) {
        const k = pairKey(seq[i], seq[i+1]);
        counts.set(k, (counts.get(k) || 0) + 1);
      }
    }
    lastPairCounts = counts;
    return counts;
  }

  function topPairs(counts, k=25) {
    const arr = [];
    for (const [key, c] of counts.entries()) {
      const [a, b] = key.split(SEP);
      arr.push({ a, b, c });
    }
    arr.sort((x, y) => y.c - x.c || (x.a + SEP + x.b).localeCompare(y.a + SEP + y.b));
    return arr.slice(0, k);
  }

  function bestPair(counts) {
    let best = null;
    for (const [key, c] of counts.entries()) {
      if (!best || c > best.c || (c === best.c && key.localeCompare(best.key) < 0)) {
        const [a, b] = key.split(SEP);
        best = { key, a, b, c };
      }
    }
    return best;
  }

  function mergeAllInSequence(seq, a, b, merged) {
    const out = [];
    for (let i = 0; i < seq.length; i++) {
      if (i < seq.length - 1 && seq[i] === a && seq[i+1] === b) {
        out.push(merged);
        i++; // skip next
      } else {
        out.push(seq[i]);
      }
    }
    return out;
  }

  function applyMerge(a, b, countAtMerge) {
    const merged = a + b;
    // Update sequences by merging all occurrences
    sequences = sequences.map(seq => mergeAllInSequence(seq, a, b, merged));
    merges.push({ a, b, merged, countAtMerge });

    // update vocab set
    vocabSet.add(merged);

    mergesPill.textContent = String(merges.length);
    vocabPill.textContent = String(vocabSet.size);
    symbolsPill.textContent = String(totalSymbolCount(sequences));

    undoBtn.disabled = !(initialized && merges.length > 0);
    updateAllViews();

    if (initialized && autoTokenize.checked) tokenizeInput();
  }

  function doBestStep() {
    if (!initialized) return false;
    const counts = computePairCounts();
    const best = bestPair(counts);
    if (!best || best.c <= 0) return false;
    applyMerge(best.a, best.b, best.c);
    return true;
  }

  function rebuildFromBase() {
    // Re-apply merges from scratch (used for undo)
    sequences = baseSequences.map(seq => seq.slice());
    vocabSet = new Set();
    for (const seq of sequences) for (const s of seq) vocabSet.add(s);

    for (const m of merges) {
      sequences = sequences.map(seq => mergeAllInSequence(seq, m.a, m.b, m.merged));
      vocabSet.add(m.merged);
    }

    mergesPill.textContent = String(merges.length);
    vocabPill.textContent = String(vocabSet.size);
    symbolsPill.textContent = String(totalSymbolCount(sequences));
  }

  function undoOne() {
    if (!initialized || merges.length === 0) return;
    merges.pop();
    rebuildFromBase();
    undoBtn.disabled = !(initialized && merges.length > 0);
    updateAllViews();
    if (autoTokenize.checked) tokenizeInput();
  }

  async function runSteps(n) {
    if (!initialized) return;
    isRunning = true;
    stopBtn.disabled = false;
    runBtn.disabled = true;
    stepBtn.disabled = true;
    initBtn.disabled = true;
    undoBtn.disabled = true;

    const max = Math.max(1, Math.min(500, Number.parseInt(n, 10) || 10));
    for (let i = 0; i < max; i++) {
      if (!isRunning) break;
      const ok = doBestStep();
      if (!ok) break;
      // Yield to keep UI responsive
      await new Promise(r => requestAnimationFrame(r));
    }

    isRunning = false;
    stopBtn.disabled = true;
    runBtn.disabled = !initialized;
    stepBtn.disabled = !initialized;
    initBtn.disabled = false;
    undoBtn.disabled = !(initialized && merges.length > 0);
  }

  function stopRunning() {
    isRunning = false;
  }

  function updateAllViews() {
    if (!initialized) {
      bestPairPill.textContent = "-";
      bestCountPill.textContent = "-";
      pairsTableWrap.innerHTML = "<div class='muted'>(initialize first)</div>";
      corpusView.innerHTML = "<div class='muted'>(initialize first)</div>";
      mergeHistory.innerHTML = "(none yet)";
      vocabView.innerHTML = "(initialize first)";
      return;
    }

    // Pair counts + best
    const counts = computePairCounts();
    const best = bestPair(counts);

    if (best) {
      bestPairPill.textContent = `${displayToken(best.a)} + ${displayToken(best.b)} → ${displayToken(best.a + best.b)}`;
      bestCountPill.textContent = String(best.c);
    } else {
      bestPairPill.textContent = "(no pairs)";
      bestCountPill.textContent = "0";
    }

    renderPairsTable(counts, best);
    renderCorpusView();
    renderMergeHistory();
    renderVocab();
  }

  function renderPairsTable(counts, best) {
    const top = topPairs(counts, 20);
    if (top.length === 0) {
      pairsTableWrap.innerHTML = "<div class='muted'>(no pairs found)</div>";
      return;
    }

    const maxC = top[0].c || 1;

    const table = document.createElement("table");
    table.innerHTML = `
      <thead>
        <tr>
          <th style="width: 56%;">pair</th>
          <th style="width: 18%;">count</th>
          <th style="width: 16%;">share</th>
          <th style="width: 10%;"></th>
        </tr>
      </thead>
      <tbody></tbody>
    `;
    const tbody = table.querySelector("tbody");

    for (const p of top) {
      const tr = document.createElement("tr");
      const isBest = best && p.a === best.a && p.b === best.b;

      const pairText = `${displayToken(p.a)} + ${displayToken(p.b)} → ${displayToken(p.a + p.b)}`;
      const share = Math.max(0, Math.min(100, (p.c / maxC) * 100));

      tr.innerHTML = `
        <td>${isBest ? "<strong>" + escapeHtml(pairText) + "</strong>" : escapeHtml(pairText)}</td>
        <td>${p.c}</td>
        <td>
          <div class="bar" title="relative to top pair">
            <div style="width:${share.toFixed(1)}%"></div>
          </div>
        </td>
        <td></td>
      `;

      const btn = document.createElement("button");
      btn.textContent = "Merge";
      btn.title = "Apply this merge (explore alternatives)";
      btn.disabled = isRunning;
      btn.addEventListener("click", () => applyMerge(p.a, p.b, p.c));

      tr.children[3].appendChild(btn);
      tbody.appendChild(tr);
    }

    pairsTableWrap.innerHTML = "";
    pairsTableWrap.appendChild(table);
  }

  function renderMergeHistory() {
    if (merges.length === 0) {
      mergeHistory.innerHTML = "(none yet)";
      return;
    }
    const lines = merges.slice(-60).map((m, i) => {
      const step = merges.length - (merges.slice(-60).length) + i + 1;
      return `<div class="small">#${step}: <code class="k">${escapeHtml(displayToken(m.a))}</code> + <code class="k">${escapeHtml(displayToken(m.b))}</code> → <code class="k">${escapeHtml(displayToken(m.merged))}</code> (count=${m.countAtMerge})</div>`;
    }).join("");
    mergeHistory.innerHTML = lines;
  }

  function renderVocab() {
    const tokens = Array.from(vocabSet);
    // Sort: shorter first then lexicographic (helps show characters early)
    tokens.sort((a, b) => a.length - b.length || a.localeCompare(b));

    const shown = tokens.slice(0, 200);
    const chips = shown.map(t => `<span class="chip" title="${escapeHtml(t)}">${escapeHtml(displayToken(t))}</span>`).join(" ");
    vocabView.innerHTML = `
      <div class="muted">Showing ${shown.length} / ${tokens.length} tokens</div>
      <div class="chipRow" style="margin-top:8px;">${chips}</div>
    `;
  }

  function renderCorpusView() {
    const k = Math.max(1, Math.min(200, Number.parseInt(showLines.value, 10) || 10));
    const lines = sequences.slice(0, k);

    if (lines.length === 0) {
      corpusView.innerHTML = "<div class='muted'>(no lines)</div>";
      return;
    }

    const html = lines.map((seq, idx) => {
      const chips = seq.slice(0, 260).map(tok => {
        const shown = displayToken(tok);
        const title = tok === SPACE_MARK ? "whitespace marker" : tok;
        // emphasize tokens that include the whitespace marker (common in real tokenizers)
        const strong = tok.includes(SPACE_MARK) ? " strong" : "";
        return `<span class="chip${strong}" title="${escapeHtml(title)}">${escapeHtml(shown)}</span>`;
      }).join(" ");

      const trimmed = seq.length > 260 ? `<span class="muted">… (+${seq.length - 260} more tokens)</span>` : "";
      return `
        <div style="margin-bottom: 10px;">
          <div class="muted">Line ${idx + 1} (${seq.length} tokens):</div>
          <div class="chipRow" style="margin-top: 6px;">${chips} ${trimmed}</div>
        </div>
      `;
    }).join("");

    corpusView.innerHTML = html;
  }

  // ===== Encoding new text with learned merges =====
  function buildMergeRank() {
    // pair -> rank (lower is earlier/higher priority)
    const rank = new Map();
    for (let i = 0; i < merges.length; i++) {
      const m = merges[i];
      rank.set(pairKey(m.a, m.b), i);
    }
    return rank;
  }

  function normalizeInput(s) {
    let t = s;
    if (lowercase.checked) t = t.toLowerCase();
    if (collapseWs.checked) t = t.replace(/\s+/g, " ").trim();
    else t = t.trim();
    if (!t) return "";
    t = SPACE_MARK + t;
    t = t.replaceAll(" ", SPACE_MARK);
    return t;
  }

  function encodeWithSteps(raw) {
    const norm = normalizeInput(raw);
    if (!norm) return { tokens: [], steps: [] };

    let symbols = Array.from(norm);
    const rank = buildMergeRank();
    const steps = [];

    // Repeatedly find the best-ranked mergeable adjacent pair in the current symbol list
    while (true) {
      let bestIdx = -1;
      let bestR = Infinity;
      let bestA = null;
      let bestB = null;

      for (let i = 0; i < symbols.length - 1; i++) {
        const k = pairKey(symbols[i], symbols[i+1]);
        const r = rank.get(k);
        if (r !== undefined && r < bestR) {
          bestR = r;
          bestIdx = i;
          bestA = symbols[i];
          bestB = symbols[i+1];
        }
      }

      if (bestIdx < 0) break;

      const merged = bestA + bestB;

      // Merge ALL occurrences of that best-ranked pair (common BPE encoding approach)
      const before = symbols;
      symbols = mergeAllInSequence(symbols, bestA, bestB, merged);

      steps.push({
        pair: [bestA, bestB],
        merged,
        rank: bestR,
        before,
        after: symbols
      });

      // Safety: prevent infinite loops (should not happen)
      if (steps.length > 2000) break;
    }

    return { tokens: symbols, steps };
  }

  function renderTokens(tokens) {
    tokenOutput.innerHTML = "";
    if (tokens.length === 0) {
      tokenOutput.innerHTML = "<span class='muted'>(empty)</span>";
      tokenStats.textContent = "";
      return;
    }

    for (const tok of tokens) {
      const span = document.createElement("span");
      span.className = "chip" + (tok.includes(SPACE_MARK) ? " strong" : "");
      span.textContent = displayToken(tok);
      span.title = tok;
      tokenOutput.appendChild(span);
    }

    tokenStats.textContent = `Token count: ${tokens.length}`;
  }

  function renderEncodeSteps(steps) {
    if (steps.length === 0) {
      encodeSteps.innerHTML = "<div class='muted'>(no merges applied during encoding)</div>";
      return;
    }

    const maxShow = 60;
    const shown = steps.slice(0, maxShow);

    const html = shown.map((s, i) => {
      const pairText = `${displayToken(s.pair[0])} + ${displayToken(s.pair[1])} → ${displayToken(s.merged)} (rank=${s.rank})`;

      const before = s.before.map(t => `<span class="chip">${escapeHtml(displayToken(t))}</span>`).join(" ");
      const after  = s.after.map(t  => `<span class="chip strong">${escapeHtml(displayToken(t))}</span>`).join(" ");

      return `
        <div style="margin-bottom: 12px;">
          <div class="muted">Step ${i + 1}: <code class="k">${escapeHtml(pairText)}</code></div>
          <div class="muted" style="margin-top: 6px;">Before:</div>
          <div class="chipRow" style="margin-top: 6px;">${before}</div>
          <div class="muted" style="margin-top: 6px;">After:</div>
          <div class="chipRow" style="margin-top: 6px;">${after}</div>
        </div>
      `;
    }).join("");

    const more = steps.length > maxShow
      ? `<div class="muted">… (${steps.length - maxShow} more encoding steps not shown)</div>`
      : "";

    encodeSteps.innerHTML = html + more;
  }

  function tokenizeInput() {
    if (!initialized) return;
    const { tokens, steps } = encodeWithSteps(inputText.value);
    renderTokens(tokens);
    renderEncodeSteps(steps);
  }

  // ===== Event wiring =====
  initBtn.addEventListener("click", init);

  undoBtn.addEventListener("click", () => {
    undoOne();
  });

  stepBtn.addEventListener("click", () => {
    doBestStep();
  });

  runBtn.addEventListener("click", async () => {
    await runSteps(runN.value);
  });

  stopBtn.addEventListener("click", stopRunning);

  refreshCorpusBtn.addEventListener("click", renderCorpusView);

  tokenizeBtn.addEventListener("click", tokenizeInput);

  // When display options change, re-render views (no re-training needed)
  showSpaceAsVisible.addEventListener("change", () => {
    updateAllViews();
    if (autoTokenize.checked) tokenizeInput();
  });

  // If preprocessing options change, re-initialize (since token base changes)
  lowercase.addEventListener("change", () => init());
  collapseWs.addEventListener("change", () => init());

  showLines.addEventListener("change", renderCorpusView);

  inputText.addEventListener("input", () => {
    if (initialized && autoTokenize.checked) tokenizeInput();
  });

  fileInput.addEventListener("change", async (e) => {
    const file = e.target.files && e.target.files[0];
    if (!file) return;
    try {
      const text = await file.text();
      corpusText.value = text;
      init(); // auto initialize after loading
    } catch {
      alert("Failed to read the file. Please try another .txt file.");
    } finally {
      fileInput.value = "";
    }
  });

  // Enable/disable controls based on state
  function syncControls() {
    undoBtn.disabled = !(initialized && merges.length > 0) || isRunning;
    stepBtn.disabled = !initialized || isRunning;
    runBtn.disabled = !initialized || isRunning;
    stopBtn.disabled = !isRunning;
    tokenizeBtn.disabled = !initialized;
    refreshCorpusBtn.disabled = !initialized;
  }

  // Patch into update cycle
  const _updateAllViews = updateAllViews;
  updateAllViews = function() {
    _updateAllViews();
    syncControls();
  };

  // ===== Boot: auto-load sample and initialize =====
  corpusText.value = DEFAULT_SAMPLE;
  init();
})();
</script>
</body>
</html>
